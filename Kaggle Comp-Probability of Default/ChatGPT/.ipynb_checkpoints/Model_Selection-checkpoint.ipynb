{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c723b0-ad6b-40fe-a2e5-f07b56c4b811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.9\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8352e9a8-adc4-46fa-80bc-71781edeeca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking import\n",
      "Taking rest for { abc } seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from Feature_Engineering import test, rest\n",
    "\n",
    "class FTTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, depth=6, heads=8, dropout=0.1):\n",
    "        super(FTTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, 128)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=128, nhead=heads, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer_encoder(x.unsqueeze(1)).squeeze(1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class LoanStatusModel:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.df = None\n",
    "        self.model = None\n",
    "        self.features = []\n",
    "        self.train_loader = None\n",
    "        self.test_loader = None\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def load_and_preprocess_data(self):\n",
    "        self.df = pd.read_csv(self.file_path)\n",
    "        target_col = \"loan_status\"\n",
    "        self.features = self.df.drop(columns=[target_col]).columns.tolist()\n",
    "        \n",
    "        X = self.df[self.features].values.astype(np.float32)\n",
    "        y = self.df[target_col].values.astype(np.int64)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        train_dataset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "        test_dataset = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n",
    "        \n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "        self.test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    def initialize_model(self):\n",
    "        self.model = FTTransformer(input_dim=len(self.features), num_classes=2)\n",
    "    \n",
    "    def train_model(self):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=2e-5)\n",
    "        \n",
    "        epochs = 10\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            for X_batch, y_batch in self.train_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(X_batch)\n",
    "                loss = criterion(output, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            print(f\"Epoch {epoch+1}, Loss: {total_loss/len(self.train_loader):.4f}\")\n",
    "        \n",
    "        torch.save(self.model.state_dict(), \"./ft_transformer_loan_model.pth\")\n",
    "    \n",
    "    def plot_data_distribution(self):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        self.df['loan_status'].value_counts().plot(kind='bar', color=['blue', 'orange'])\n",
    "        plt.xlabel('Loan Status')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Loan Status Distribution')\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n",
    "    rest('abc')\n",
    "    loan_model = LoanStatusModel(\"..\\\\ChatGPT\\\\processed_data\\\\feature_engineered.csv\")\n",
    "    loan_model.load_and_preprocess_data()\n",
    "    loan_model.initialize_model()\n",
    "    loan_model.train_model()\n",
    "    loan_model.plot_data_distribution()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
